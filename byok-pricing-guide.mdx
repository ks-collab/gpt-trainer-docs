---
title: Bring Your Own Key (BYOK) and Pricing
---

GPT-trainer operates on a "pay as you go" basis. Rather than having Message Credits (MCs) baked into existing subscriptions, you 
buy them separately via add-ons or connect your own AI API keys to enjoy unlimited usage.

If you use your own AI API keys, then after you exhaust all MCs inside your GPT-trainer account, additional AI usage will be charged 
against your own API keys.

## Setting up BYOK

To set up your own API key, you will first need to register on the AI provider's website. GPT-trainer currently 
supports large language models (LLMs) from OpenAI, Anthropic, and Google. In the future, we plan to expand our list of supported 
models, potentially incorporating open-source and fine-tuned ones.

### Provider-specific instructions
- OpenAI (GPT models)- https://platform.openai.com/account/api-keys
- Anthropic (Claude models) - https://console.anthropic.com/settings/keys
- Google (Gemini models) - https://ai.google.dev/gemini-api/docs/api-key

After you obtain your API key, store it in a **private and secure** location. GPT-trainer recommends that you use a separate API 
key for each of your BYOK applications (including GPT-trainer), and to never share your API key with anyone else.

Next, log in to GPT-trainer and go to the top right corner of the UI. Click the "Profile" icon the bring up a dropdown menu.

<Frame>
  <img src="/images/byok-pricing-guide-1.png" />
</Frame>

Then, click "Account". In the **"AI API Key"** section, pick your AI provider and paste your API key. Then click "Add". 
Please note that this is **not** the "GPT-trainer API keys" section which is used to generate GPT-trainer API keys.

<Frame>
  <img src="/images/byok-pricing-guide-3.png" />
</Frame>

You should be all set.

<Note>
  If this is the first time you create an API key with a provider, there is a good chance that your key may be rate and 
  feature limited. For example, as of November 1, 2024, all new API keys registered with new OpenAI accounts are prohibited from running 
  GPT-4o model series.
  
  To lift this restriction, you may need to add $5 credt and provide verified billing information within your OpenAI account. Different 
  providers may have different policies regarding account verification. 
</Note>

## Budgeting for AI usage

In general, using your own API key will be more cost efficient than purchasing MC add-ons directly. To help you estimate costs 
associated with running your BYOK account, we provide the following references.

<Note>
  LLM providers change their pricing from time to time, so the information we provide may not always be up-to-date.
  For latest information on pricing, please visit:
  - OpenAI (GPT models): https://openai.com/pricing
  - Anthropic (Claude models): https://www.anthropic.com/pricing#anthropic-api
  - Google (Gemini models): https://ai.google.dev/pricing#1_5flash
</Note>

The simplest estimate you can use is this:

- Each Message Credit costs ~$0.0032 USD

For example, GPT-4-1106-4k uses 20 MCs per query. To estimate the cost in USD, multiply \$0.0032 * 20 = \$0.064 USD.

This is a very rough estimate. Actual spend may be around +/- 20% of the estimated number. This is because LLM usage is measured 
based on "tokens", and input vs. output tokens cost different amounts even for the same LLM. To understand tokens, we 
refer you to this article: https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them.

There are many parts to a LLM query. At a high level, they can be broken down into:

Input:
- System prompt and metadata
- User-defined base prompt
- Variables and definitions
- Conversation label definitions
- Function metadata and descriptions
- Function parameters
- Function response
- Static RAG context
- Conversation memory

Output:
- Text response
- Response metadata

### OpenAI pricing breakdown

GPT-trainer supports a variety of OpenAI LLMs, as well as different versions of the same LLM with custom token limit cutoffs. 
To help you budget for your usage, we provide a summary based on our **default** split of reserved input vs. output tokens. Please refer 
to the following table (all \$ are in USD). Please note that this generally represents an upper limit since not all input / output tokens 
in the reservation window are used every single LLM query.

| Model           | Reserved for Input | Reserved for Output | Cost / Input Token | Cost / Output Token | Total Cost per Query |
| --------------- | ------------------ | ------------------- | ------------------ | ------------------- | -------------------- |
| GPT-3.5         | 2800               | 1200                | 0.0000005          | 0.0000015           | 0.0032               |
| GPT-3.5-16k     | 13600              | 2400                | 0.0000005          | 0.0000015           | 0.0104               |
| GPT-4o-mini-1k  | 800                | 200                 | 0.00000015         | 0.0000006           | 0.00024              |
| GPT-4o-mini-2k  | 1600               | 400                 | 0.00000015         | 0.0000006           | 0.00048              |
| GPT-4o-mini-4k  | 2800               | 1200                | 0.00000015         | 0.0000006           | 0.00114              |
| GPT-4o-mini-8k  | 5600               | 2400                | 0.00000015         | 0.0000006           | 0.00228              |
| GPT-4o-mini-16k | 12800              | 3200                | 0.00000015         | 0.0000006           | 0.00384              |
| GPT-4o-mini-32k | 28000              | 4000                | 0.00000015         | 0.0000006           | 0.0066               |
| GPT-4o-mini-64k | 60000              | 4000                | 0.00000015         | 0.0000006           | 0.0114               |
| GPT-4o-1k       | 800                | 200                 | 0.0000025          | 0.00001             | 0.004                |
| GPT-4o-2k       | 1600               | 400                 | 0.0000025          | 0.00001             | 0.008                |
| GPT-4o-4k       | 2800               | 1200                | 0.0000025          | 0.00001             | 0.019                |
| GPT-4o-8k       | 5600               | 2400                | 0.0000025          | 0.00001             | 0.038                |
| GPT-4o-16k      | 12800              | 3200                | 0.0000025          | 0.00001             | 0.064                |
| GPT-4o-32k      | 28000              | 4000                | 0.0000025          | 0.00001             | 0.11                 |
| GPT-4o-64k      | 60000              | 4000                | 0.0000025          | 0.00001             | 0.19                 |
| GPT-4-1106-1k   | 800                | 200                 | 0.00001            | 0.00003             | 0.014                |
| GPT-4-1106-2k   | 1600               | 400                 | 0.00001            | 0.00003             | 0.028                |
| GPT-4-1106-4k   | 2800               | 1200                | 0.00001            | 0.00003             | 0.064                |
| GPT-4-0125-8k   | 5600               | 2400                | 0.00001            | 0.00003             | 0.128                |
| GPT-4-1106-16k  | 12800              | 3200                | 0.00001            | 0.00003             | 0.224                |
| GPT-4-1106-32k  | 28000              | 4000                | 0.00001            | 0.00003             | 0.4                  |
| GPT-4-1106-64k  | 60000              | 4000                | 0.00001            | 0.00003             | 0.72                 |

## BYOK for white-label commercial partners

In addition to the costs for MC expenditures during LLM queries, you also need to pay to run our AI multi-agent framework using your 
own API key. This is independent of whether your users have supplied their API key for their personal accounts. Since the official GPT-trainer 
subsidizes its users for all costs associated with running the AI framework, your white-label solution must operate with this premise 
as well.

There are three separate workflows that require your own API key to cover your user's AI expenditures. The conditions under which they apply 
are listed below.

1. AI Agent intent generation
  - Applicable if two or more AI Agents are connected
  - Charged whenever a new user-facing AI Agent goes live or an existing one is edited
2. Query intent classification
  - Applicable if two or more user-facing Agents are connected
  - Charged on a per query basis
3. Variable extraction
  - Applicable if AI Agent has one or more variables set up
  - Charged on a per query basis


The estimated costs associated with each workflow is as follows:

| Workflow                                           | Average Estimated Input | Average Estimated Output | Cost / Input Token | Cost / Output Token | Estimated Cost per Run |
| -------------------------------------------------- | ----------------------- | ------------------------ | ------------------ | ------------------- | ---------------------- |
| AI Agent intent generation (gpt-4-1106-preview)    | 600                     | 450                      | 0.00001            | 0.00003             | 0.0011                 |
| Query intent classification (gpt-3.5-turbo-1106)   | 1000                    | 50                       | 0.000001           | 0.000002            | 0.0195                 |
| Variables extraction (gpt-3.5-turbo-1106)          | 1000                    | 100                      | 0.000001           | 0.000002            | 0.0012                 |

All costs from the above workflow will be charged directly against your own API key. This cost cannot be transferred onto your clients.

There may be more AI features in the future that require using your own API key. We will update the documentation as needed to help you plan ahead. 
However, in general, these extra API costs should be fairly negligible in comparison to AI costs associated with Message Credit expenditures.